# ðŸ” Duplicate Questions Detection using NLP

**Duplicate Questions Detection** â€” Ð¿Ñ€Ð¾Ñ”ÐºÑ‚ Ð´Ð»Ñ ÐºÐ»Ð°ÑÐ¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ— Ð¿Ð°Ñ€ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¸Ñ… Ð·Ð°Ð¿Ð¸Ñ‚Ð°Ð½ÑŒ Ñ– Ð¿ÐµÑ€ÐµÐ´Ð±Ð°Ñ‡ÐµÐ½Ð½Ñ **Ð¹Ð¼Ð¾Ð²Ñ–Ñ€Ð½Ð¾ÑÑ‚Ñ–**, Ñ‰Ð¾ Ð¿Ð°Ñ€Ð° Ñ” Ð´ÑƒÐ±Ð»Ñ–ÐºÐ°Ñ‚Ð¾Ð¼ (Ð¼Ð°Ñ” Ð¾Ð´Ð½Ð°ÐºÐ¾Ð²Ð¸Ð¹ Ð·Ð¼Ñ–ÑÑ‚).

## 2. Ð‘Ñ–Ð·Ð½ÐµÑ-Ð·Ð°Ð´Ð°Ñ‡Ð° Ñ‚Ð° Ð¼ÐµÑ‚Ð°
Ð‘Ñ–Ð·Ð½ÐµÑ-Ð·Ð°Ð´Ð°Ñ‡Ð° â€” Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾ Ð·Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚Ð¸ Ð´ÑƒÐ±Ð»ÑŒÐ¾Ð²Ð°Ð½Ð¸Ð¹/ÑÑ…Ð¾Ð¶Ð¸Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚. Ð¦Ðµ ÐºÐ¾Ñ€Ð¸ÑÐ½Ð¾ Ð´Ð»Ñ:
- Ð¿Ð¾ÑˆÑƒÐºÑƒ ÑÑ…Ð¾Ð¶Ð¸Ñ… Ð½Ð°Ð·Ð² Ñ‚Ð¾Ð²Ð°Ñ€Ñ–Ð² Ð½Ð° Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¿Ð»ÐµÐ¹ÑÐ°Ñ…,
- Ð²Ð¸ÑÐ²Ð»ÐµÐ½Ð½Ñ Ð´ÑƒÐ±Ð»ÑŒÐ¾Ð²Ð°Ð½Ð¸Ñ… Ð·Ð°Ð¿Ð¸ÑÑ–Ð² Ñƒ Ð±Ð°Ð·Ð°Ñ… ÐºÐ»Ñ–Ñ”Ð½Ñ‚Ñ–Ð²,
- Ð³Ñ€ÑƒÐ¿ÑƒÐ²Ð°Ð½Ð½Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑŽÐ²Ð°Ð½Ð¸Ñ… Ð·Ð°Ð¿Ð¸Ñ‚Ñ–Ð² Ñƒ Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½ÑÑ…/Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼Ñ†Ñ–.
ÐœÐµÑ‚Ð° â€” Ð¿Ð¾Ð±ÑƒÐ´ÑƒÐ²Ð°Ñ‚Ð¸ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ñ‚Ð¾Ñ‡Ð½Ñƒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ñƒ Ð¹Ð¼Ð¾Ð²Ñ–Ñ€Ð½Ð¾ÑÑ‚Ñ– Ð´ÑƒÐ±Ð»Ñ–ÐºÐ°Ñ‚Ð°.

## 3. Ð”Ð°Ð½Ñ–
- **Ð”Ð¶ÐµÑ€ÐµÐ»Ð¾:** Quora Question Pairs (Kaggle) â€” https://www.kaggle.com/c/quora-question-pairs  
- **Ð Ð¾Ð·Ð¼Ñ–Ñ€:** Train â‰ˆ 323 000 Ð¿Ð°Ñ€, Test â‰ˆ 80 000 Ð¿Ð°Ñ€  
- **ÐžÐ¿Ð¸Ñ:** `question1`, `question2`, Ð¼Ñ–Ñ‚ÐºÐ° `label` (1 â€” Ð´ÑƒÐ±Ð»Ñ–ÐºÐ°Ñ‚Ð¸, 0 â€” Ð½Ðµ Ð´ÑƒÐ±Ð»Ñ–ÐºÐ°Ñ‚Ð¸).

## 4. ÐŸÑ–Ð´Ñ…Ñ–Ð´ Ð´Ð¾ Ð¾Ñ†Ñ–Ð½ÑŽÐ²Ð°Ð½Ð½Ñ, Ð¾Ð±Ñ€Ð°Ð½Ð° Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°
Ð—Ð°Ð´Ð°Ñ‡Ð° â€” Ð±Ñ–Ð½Ð°Ñ€Ð½Ð° ÐºÐ»Ð°ÑÐ¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ Ð· Ñ–Ð¼Ð¾Ð²Ñ–Ñ€Ð½Ñ–ÑÐ½Ð¸Ð¼ Ð²Ð¸Ñ…Ð¾Ð´Ð¾Ð¼.
- **ÐžÑÐ½Ð¾Ð²Ð½Ð° Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ°:** LogLoss (ÑÐºÑ–ÑÑ‚ÑŒ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ð¾Ð²Ð°Ð½Ð¸Ñ… Ð¹Ð¼Ð¾Ð²Ñ–Ñ€Ð½Ð¾ÑÑ‚ÐµÐ¹)
- **Ð”Ð¾Ð´Ð°Ñ‚ÐºÐ¾Ð²Ñ–:** F1-score, Accuracy

## 5. ÐŸÑ–Ð´Ñ…Ñ–Ð´ Ð´Ð¾ Ñ€Ð¾Ð·Ð²'ÑÐ·ÐºÑƒ, Ñ–Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¸
- Baseline Ð¼Ð¾Ð´ÐµÐ»Ñ– Ð½Ð° Ð¿Ñ€Ð¾ÑÑ‚Ð¸Ñ… Ð¾Ð·Ð½Ð°ÐºÐ°Ñ….
- Sentence-BERT embeddings Ð´Ð»Ñ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡Ð½Ð¸Ñ… Ð¾Ð·Ð½Ð°Ðº.
- PCA Ð´Ð»Ñ Ð·Ð¼ÐµÐ½ÑˆÐµÐ½Ð½Ñ Ñ€Ð¾Ð·Ð¼Ñ–Ñ€Ð½Ð¾ÑÑ‚Ñ– embeddings.
- ÐžÐ·Ð½Ð°ÐºÐ¸ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ñ– embeddings: cosine similarity, |q1âˆ’q2| (Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ð° Ñ€Ñ–Ð·Ð½Ð¸Ñ†Ñ), q1Â·q2 (Ð¿Ð¾ÐµÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð½Ð¸Ð¹ Ð´Ð¾Ð±ÑƒÑ‚Ð¾Ðº).
- Ð”Ð¾Ð´Ð°Ñ‚ÐºÐ¾Ð²Ñ– Ð»ÐµÐºÑÐ¸Ñ‡Ð½Ñ– Ð¾Ð·Ð½Ð°ÐºÐ¸: TF-IDF cosine similarity, ÐºÑ–Ð»ÑŒÐºÑ–ÑÑ‚ÑŒ ÑÐ¿Ñ–Ð»ÑŒÐ½Ð¸Ñ… ÑÐ»Ñ–Ð².
- Ð¤Ñ–Ð½Ð°Ð»ÑŒÐ½Ð¸Ð¹ ÐºÐ»Ð°ÑÐ¸Ñ„Ñ–ÐºÐ°Ñ‚Ð¾Ñ€: Logistic Regression (lbfgs).
Ð†Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¸: Python, NumPy, Pandas, scikit-learn, sentence-transformers, Jupyter/Colab.

## 6. Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¸ (Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ ÐµÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ñ–Ð²)
| ÐœÐ¾Ð´ÐµÐ»ÑŒ                                   | ÐžÐ·Ð½Ð°ÐºÐ¸                                                                 | LogLoss |  F1   | Accuracy |
|------------------------------------------|------------------------------------------------------------------------|---------|-------|----------|
| Baseline LogReg                          | TF-IDF cosine similarity Ð¼Ñ–Ð¶ question1 Ñ‚Ð° question2                    | ~0.47   | ~0.71 | ~0.77    |
| LogReg + SBERT (Ð¿Ð¾Ð²Ð½Ñ– Ð¾Ð·Ð½Ð°ÐºÐ¸)            | Sentence-BERT embeddings (384) + cosine similarity + |q1âˆ’q2| + q1Â·q2  | ~0.41   | ~0.74 | ~0.78    |
| SBERT + Ð°Ð³Ñ€ÐµÐ³Ð°Ñ‚Ð¸                         | Sentence-BERT embeddings + Ð°Ð³Ñ€ÐµÐ³Ð°Ñ‚Ð¸ Ñ€Ñ–Ð·Ð½Ð¸Ñ†Ñ– Ñ‚Ð° Ð´Ð¾Ð±ÑƒÑ‚ÐºÑƒ (mean, max, L2) | >0.41   | <0.74 | ~0.77    |
| SBERT + PCA (64)                         | Sentence-BERT â†’ PCA (64) + |q1âˆ’q2| + q1Â·q2 + cosine similarity          | ~0.398  | ~0.757| ~0.80    |
| **SBERT + PCA + TF-IDF + common words**  | **PCA(64) + |q1âˆ’q2| + q1Â·q2 + TF-IDF cosine + ÐºÑ–Ð»ÑŒÐºÑ–ÑÑ‚ÑŒ ÑÐ¿Ñ–Ð»ÑŒÐ½Ð¸Ñ… ÑÐ»Ñ–Ð²** | **0.3875** | **0.7640** | **0.81** |



## 7. Ð’Ð¸ÑÐ½Ð¾Ð²ÐºÐ¸
ÐÐ°Ð¹ÐºÑ€Ð°Ñ‰Ð¸Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð´Ð°Ð»Ð° ÐºÐ¾Ð¼Ð±Ñ–Ð½Ð°Ñ†Ñ–Ñ **Sentence-BERT + PCA** (Ð´Ð»Ñ ÑÑ‚Ð°Ð±Ñ–Ð»ÑŒÐ½Ð¾ÑÑ‚Ñ– Ñ‚Ð° Ð·Ð¼ÐµÐ½ÑˆÐµÐ½Ð½Ñ Ñ€Ð¾Ð·Ð¼Ñ–Ñ€Ð½Ð¾ÑÑ‚Ñ–) Ñ‚Ð° Ð¿Ñ€Ð¾ÑÑ‚Ð¸Ñ… Ð»ÐµÐºÑÐ¸Ñ‡Ð½Ð¸Ñ… Ð¾Ð·Ð½Ð°Ðº (**TF-IDF cosine** Ñ– **ÐºÑ–Ð»ÑŒÐºÑ–ÑÑ‚ÑŒ ÑÐ¿Ñ–Ð»ÑŒÐ½Ð¸Ñ… ÑÐ»Ñ–Ð²**). Ð¤Ñ–Ð½Ð°Ð»ÑŒÐ½Ð° Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¼Ð°Ñ” Ð½Ð°Ð¹Ð½Ð¸Ð¶Ñ‡Ð¸Ð¹ LogLoss Ñ– Ð½Ð°Ð¹Ð²Ð¸Ñ‰Ð¸Ð¹ F1 ÑÐµÑ€ÐµÐ´ Ð¿Ñ€Ð¾Ñ‚ÐµÑÑ‚Ð¾Ð²Ð°Ð½Ð¸Ñ… Ð²Ð°Ñ€Ñ–Ð°Ð½Ñ‚Ñ–Ð².

ÐŸÑ€Ð°ÐºÑ‚Ð¸Ñ‡Ð½Ð¸Ð¹ Ñ–Ð½ÑÐ°Ð¹Ñ‚, Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ð½Ð¸Ð¹ Ñƒ Ñ…Ð¾Ð´Ñ– ÐµÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ñ–Ð², Ð¿Ð¾Ð»ÑÐ³Ð°Ñ” Ð² Ñ‚Ð¾Ð¼Ñƒ, Ñ‰Ð¾ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡Ð½Ñ– embeddingÐ¸ Ð´Ð¾Ð±Ñ€Ðµ Ð²Ð¸ÑÐ²Ð»ÑÑŽÑ‚ÑŒ ÑÑ…Ð¾Ð¶Ñ–ÑÑ‚ÑŒ Ð·Ð° Ð·Ð¼Ñ–ÑÑ‚Ð¾Ð¼, Ð°Ð»Ðµ Ð¼Ð¾Ð¶ÑƒÑ‚ÑŒ Ð¿ÐµÑ€ÐµÐ¾Ñ†Ñ–Ð½ÑŽÐ²Ð°Ñ‚Ð¸ Ð¿Ð¾Ð´Ñ–Ð±Ð½Ñ–ÑÑ‚ÑŒ Ð¼Ñ–Ð¶ Ñ€Ñ–Ð·Ð½Ð¸Ð¼Ð¸ Ñ„Ð¾Ñ€Ð¼ÑƒÐ»ÑŽÐ²Ð°Ð½Ð½ÑÐ¼Ð¸. 

Ð”Ð¾Ð´Ð°Ð²Ð°Ð½Ð½Ñ Ð»ÐµÐºÑÐ¸Ñ‡Ð½Ð¸Ñ… Ð¾Ð·Ð½Ð°Ðº Ð´Ð¾Ð·Ð²Ð¾Ð»ÑÑ” Ð·Ð¼ÐµÐ½ÑˆÐ¸Ñ‚Ð¸ ÐºÑ–Ð»ÑŒÐºÑ–ÑÑ‚ÑŒ Ñ…Ð¸Ð±Ð½Ð¾Ð¿Ð¾Ð·Ð¸Ñ‚Ð¸Ð²Ð½Ð¸Ñ… ÑÐ¿Ñ€Ð°Ñ†ÑŒÐ¾Ð²ÑƒÐ²Ð°Ð½ÑŒ, Ð¾ÑÐºÑ–Ð»ÑŒÐºÐ¸ Ñ‚Ð°ÐºÑ– Ð¾Ð·Ð½Ð°ÐºÐ¸ Ð²Ñ€Ð°Ñ…Ð¾Ð²ÑƒÑŽÑ‚ÑŒ Ñ„Ð°ÐºÑ‚Ð¸Ñ‡Ð½Ð¸Ð¹ Ð¿ÐµÑ€ÐµÑ‚Ð¸Ð½ ÑÐ»Ñ–Ð² Ð¼Ñ–Ð¶ Ð¿Ð¸Ñ‚Ð°Ð½Ð½ÑÐ¼Ð¸. Ð—Ð°ÑÑ‚Ð¾ÑÑƒÐ²Ð°Ð½Ð½Ñ PCA Ð´Ð¾Ð´Ð°Ñ‚ÐºÐ¾Ð²Ð¾ ÑÐ¿Ñ€Ð¾ÑÑ‚Ð¸Ð»Ð¾ Ð¿Ñ€Ð¾ÑÑ‚Ñ–Ñ€ Ð¾Ð·Ð½Ð°Ðº Ñ– Ð·Ñ€Ð¾Ð±Ð¸Ð»Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð±Ñ–Ð»ÑŒÑˆ ÑÑ‚Ñ–Ð¹ÐºÐ¾ÑŽ Ð´Ð¾ ÑˆÑƒÐ¼Ñƒ.

Ð— Ñ‚Ð¾Ñ‡ÐºÐ¸ Ð·Ð¾Ñ€Ñƒ Ð±Ñ–Ð·Ð½ÐµÑ-Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ²Ð°Ð½ÑŒ, Ð·Ð°Ð¿Ñ€Ð¾Ð¿Ð¾Ð½Ð¾Ð²Ð°Ð½Ð° Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¼Ð¾Ð¶Ðµ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ²Ð°Ñ‚Ð¸ÑÑ Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð¾Ð³Ð¾ Ð²Ð¸ÑÐ²Ð»ÐµÐ½Ð½Ñ Ð´ÑƒÐ±Ð»ÑŒÐ¾Ð²Ð°Ð½Ð¾Ð³Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ñƒ Ð² Ñ€Ñ–Ð·Ð½Ð¸Ñ… ÑÐ¸ÑÑ‚ÐµÐ¼Ð°Ñ…: Ð¾Ð±â€™Ñ”Ð´Ð½Ð°Ð½Ð½Ñ ÑÑ…Ð¾Ð¶Ð¸Ñ… Ð·Ð°Ð¿Ð¸Ñ‚Ñ–Ð² ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ñ–Ð², Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð½Ñ ÐºÐ»Ñ–Ñ”Ð½Ñ‚ÑÑŒÐºÐ¸Ñ… Ð±Ð°Ð· Ð´Ð°Ð½Ð¸Ñ…, Ð¿Ð¾ÑˆÑƒÐºÑƒ ÑÑ…Ð¾Ð¶Ð¸Ñ… Ð½Ð°Ð·Ð² Ñ‚Ð¾Ð²Ð°Ñ€Ñ–Ð² Ð°Ð±Ð¾ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑŽÐ²Ð°Ð½Ð¸Ñ… Ð·Ð²ÐµÑ€Ð½ÐµÐ½ÑŒ Ñƒ ÑÐ»ÑƒÐ¶Ð±Ð°Ñ… Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÐºÐ¸. ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð¿Ñ€Ð°Ñ†ÑŽÑ” ÑˆÐ²Ð¸Ð´ÐºÐ¾, Ð½Ðµ Ð¿Ð¾Ñ‚Ñ€ÐµÐ±ÑƒÑ” ÑÐºÐ»Ð°Ð´Ð½Ð¾Ð³Ð¾ Ð´Ð¾Ð½Ð°Ð²Ñ‡Ð°Ð½Ð½Ñ Ñ‚Ð° Ð¼Ð¾Ð¶Ðµ Ð±ÑƒÑ‚Ð¸ Ð»ÐµÐ³ÐºÐ¾ Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð¾Ð²Ð°Ð½Ð° Ð² Ñ–ÑÐ½ÑƒÑŽÑ‡Ñ– Ñ–Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–Ð¹Ð½Ñ– ÑÐ¸ÑÑ‚ÐµÐ¼Ð¸.

ÐžÑÐ½Ð¾Ð²Ð½Ñ– Ð¾Ð±Ð¼ÐµÐ¶ÐµÐ½Ð½Ñ Ð¼Ð¾Ð´ÐµÐ»Ñ– Ð¿Ð¾Ð²â€™ÑÐ·Ð°Ð½Ñ– Ð· Ñ‚Ð¸Ð¼, Ñ‰Ð¾ Ð²Ð¾Ð½Ð° Ð½Ðµ Ñ” end-to-end Ð½ÐµÐ¹Ñ€Ð¾Ð½Ð½Ð¾ÑŽ Ð¼ÐµÑ€ÐµÐ¶ÐµÑŽ Ñ– Ð½Ðµ Ð½Ð°Ð²Ñ‡Ð°Ñ”Ñ‚ÑŒÑÑ Ð±ÐµÐ·Ð¿Ð¾ÑÐµÑ€ÐµÐ´Ð½ÑŒÐ¾ Ð½Ð° Ñ‚ÐµÐºÑÑ‚Ð°Ñ…. Ð¯ÐºÑ–ÑÑ‚ÑŒ Ð¿Ñ€Ð¾Ð³Ð½Ð¾Ð·Ñ–Ð² Ð·Ð½Ð°Ñ‡Ð½Ð¾ÑŽ Ð¼Ñ–Ñ€Ð¾ÑŽ Ð·Ð°Ð»ÐµÐ¶Ð¸Ñ‚ÑŒ Ð²Ñ–Ð´ ÑÐºÐ¾ÑÑ‚Ñ– Ð¿Ð¾Ð¿ÐµÑ€ÐµÐ´Ð½ÑŒÐ¾ Ð¾Ñ‚Ñ€Ð¸Ð¼Ð°Ð½Ð¸Ñ… embeddings Ñ‚Ð° Ð²Ð¸Ð±Ñ€Ð°Ð½Ð¸Ñ… Ð¾Ð·Ð½Ð°Ðº. ÐšÑ€Ñ–Ð¼ Ñ‚Ð¾Ð³Ð¾, Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¼Ð¾Ð¶Ðµ Ð¿Ð¾Ð¼Ð¸Ð»ÑÑ‚Ð¸ÑÑ Ñƒ Ð²Ð¸Ð¿Ð°Ð´ÐºÐ°Ñ…, ÐºÐ¾Ð»Ð¸ Ð·Ð°Ð¿Ð¸Ñ‚Ð°Ð½Ð½Ñ Ð¼Ð°ÑŽÑ‚ÑŒ Ð¾Ð´Ð½Ð°ÐºÐ¾Ð²Ð¸Ð¹ Ð·Ð¼Ñ–ÑÑ‚, Ð°Ð»Ðµ Ð·Ð¾Ð²ÑÑ–Ð¼ Ñ€Ñ–Ð·Ð½Ñƒ Ð»ÐµÐºÑÐ¸ÐºÑƒ.

ÐŸÐ¾Ð´Ð°Ð»ÑŒÑˆÑ– Ð½Ð°Ð¿Ñ€ÑÐ¼Ð¸ Ð¿Ð¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð½Ñ Ð¼Ð¾Ð¶ÑƒÑ‚ÑŒ Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ‚Ð¸ fine-tuning BERT-Ð¼Ð¾Ð´ÐµÐ»Ñ– Ð¿Ñ–Ð´ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñƒ Ð·Ð°Ð´Ð°Ñ‡Ñƒ, Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ cross-encoder Ð¿Ñ–Ð´Ñ…Ð¾Ð´Ñ–Ð² Ð´Ð»Ñ Ð³Ð»Ð¸Ð±ÑˆÐ¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ Ð¿Ð°Ñ€ Ñ‚ÐµÐºÑÑ‚Ñ–Ð² Ð°Ð±Ð¾ Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ²Ð°Ð½Ð½Ñ Ð±Ñ–Ð»ÑŒÑˆ ÑÐºÐ»Ð°Ð´Ð½Ð¸Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ ÐºÐ»Ð°ÑÐ¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ñ—. Ð¢Ð°ÐºÐ¾Ð¶ Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¸Ð¼ Ñ” Ñ€Ð¾Ð·ÑˆÐ¸Ñ€ÐµÐ½Ð½Ñ Ð½Ð°Ð±Ð¾Ñ€Ñƒ Ð»ÐµÐºÑÐ¸Ñ‡Ð½Ð¸Ñ… Ð¾Ð·Ð½Ð°Ðº Ñ‚Ð° Ð°Ð´Ð°Ð¿Ñ‚Ð°Ñ†Ñ–Ñ Ð¼Ð¾Ð´ÐµÐ»Ñ– Ð¿Ñ–Ð´ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ– Ð´Ð¾Ð¼ÐµÐ½Ð¸ Ð±Ñ–Ð·Ð½ÐµÑÑƒ.

## 8. Ð¯Ðº Ð·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚Ð¸ Ð¿Ñ€Ð¾Ñ”ÐºÑ‚ (Installation & Usage)
```bash
git clone <repository_url>
cd duplicate-questions-detection
pip install -r requirements.txt
jupyter notebook
